\chapter{Implementation}
\label{chapter:implementation}

%--------------------------------------------------
\section{Technology Stack}
The system is implemented in \textbf{Python~3.11} and leverages a concise set of robust open-source libraries:
\begin{itemize}
  \item \textbf{LangGraph}~\footnote{v0.0.30 at time of writing} for graph-based agent orchestration and workflow management.
  \item \textbf{PyPDF2} and \textbf{pdfminer.six} for lightweight PDF metadata inspection.
  \item \textbf{OpenAI Python SDK} for GPT-4 and GPT-4~Vision function calls.
  \item \textbf{Playwright} to drive a headless Chromium browser for Google search and captcha-free PDF downloads.
  \item \textbf{PostgreSQL~15} for durable storage of validated specification records and provenance.
\end{itemize}
GPU acceleration is optional but recommended for the VLM parsing step; the reference deployment uses an \texttt{NVIDIA~A10} with the \texttt{nvidia-container-toolkit} runtime.

%--------------------------------------------------
\section{Repository Layout}
Listing~\ref{lst:tree} shows the actual top-level directory structure. The main source code is under \texttt{src/multi\_agent\_data\_enrichment/}, with agent logic, orchestration, and tools organized by submodule. Logs, test scripts, and sample data are kept at the project root for reproducibility and debugging.

\begin{figure}[H]
\centering
\begin{minipage}{0.9\textwidth}
\begin{verbatim}
multi_agent_data_enrichment/
  cli.py
  datasheet_download.log
  datasheets/
    LM324.pdf
    LM358.pdf
    LM456.pdf
  debug_screenshots/
    ... (PNG screenshots of browser automation)
  logs/
    ... (run logs)
  pyproject.toml
  README.md
  src/
    multi_agent_data_enrichment/
      __init__.py
      graph/
        component_graph.py
      tools/
        component_tools.py
        datasheet_parse.py
        downloader.py
      visualization.py
  test_compact_viz.py
  test_real_downloader.py
  token_usage_log.csv
  uv.lock
\end{verbatim}
\end{minipage}
\caption{Abbreviated repository tree. The \texttt{src/multi\_agent\_data\_enrichment/} directory contains the main agent, orchestration, and utility modules.}
\label{lst:tree}
\end{figure}

%--------------------------------------------------
\section{Agent Implementations}
This section details the concrete logic, prompts, and error-handling behaviour of each agent introduced in Chapter~\ref{chapter:architecture}.

\subsection{MPN Extraction Agent - TODO}
The agent exposes a single LangChain \texttt{Tool} with the JSON schema in Listing~\ref{lst:mpn_schema}.  A few-shot prompt (\emph{``Identify the most probable manufacturer part number â€¦''}) primes GPT-4 with six diverse standardised quotation analysis template examples.  Post-processing removes common packaging suffixes (\texttt{-TR}, \texttt{-T/R}) and trims whitespace.  Regex validation assures an alphanumeric core of at least six characters.
\begin{figure}[H]
\centering
\begin{minipage}{0.9\textwidth}
\begin{verbatim}
{ "type": "object", "properties": {
    "mpn": {"type": "string"}
  }, "required": ["mpn"] }
\end{verbatim}
\end{minipage}
\caption{JSON schema emitted by the MPN Extraction Agent.}
\label{lst:mpn_schema}
\end{figure}

\subsection{Retrieval Agents (API)}
The retrival agent is a GBT4o based.

It can use tool to send post "October API"

\paragraph{Octopart API}  The Octopart APIs are used to query technical parameters for a given MPN. Requests are rate-limited to ten per second using an asynchronous semaphore. Each query returns a JSON message directly from Octopart.


\subsection{Retrieval Agent (PDF)}

\paragraph{Web-Search Agent}  Playwright launches a \texttt{chromium} browser in non-headed, proxy-aware mode and executes the search string:\\
\texttt{\{MPN\} datasheet filetype:pdf}.  Candidate URLs are scored by the heuristic in Equation~\ref{eq:heuristic}.  PDFs larger than 20~MB or smaller than 50~kB are discarded early to save tokens in the parsing step.

Each downloaded PDF is split into page images which are batched into groups of four to amortise API overhead.  The chain-of-thought prompt first asks GPT-4 V to produce a section outline before extracting the five target parameters (voltage, current, power, temperature, package).  The agent returns both the JSON fields and a list of (page, bbox) tuples for provenance.

\subsection{Validation Module}
Validation combines three layers:
\begin{enumerate}
  \item \textbf{JSON-Schema} checks ensure types and units.
  \item \textbf{Physical range} rules (e.g., $0< V_{\max}<1000\,\mathrm{V}$).
  \item \textbf{Cross-source consistency} compares datasheet values with Octopart metadata; discrepancies >5\,\% trigger a retry path to the Web-Search Agent.
\end{enumerate}
If validation succeeds, the record is written to PostgreSQL and an OpenTelemetry span is emitted.

%--------------------------------------------------
\section{Orchestration and State Management}
\subsection{Graph-Based Orchestration with LangGraph}

The orchestration of agent workflows is implemented using the \textbf{LangGraph} framework, which enables explicit modeling of multi-agent pipelines as directed graphs. Each node in the graph represents a discrete agent or tool (e.g., MPN extraction, Octopart API query, PDF retrieval, validation), and edges encode the allowed transitions based on success, failure, or conditional logic.

\paragraph{State Management}
LangGraph maintains a shared state object (a Python \texttt{dict}) that is passed and mutated as the workflow progresses. This state contains the current MPN, intermediate results, validation status, and error traces. Each agent node reads from and writes to this state, ensuring that context is preserved across asynchronous steps.

\paragraph{Stage Transitions}
The orchestration graph is defined in \texttt{src/multi\_agent\_data\_enrichment/graph/component\_graph.py}. The main stages are:
\begin{enumerate}
  \item \textbf{MPN Extraction}: Parses the input document or text to extract the most probable manufacturer part number.
  \item \textbf{API Retrieval}: Queries Octopart for technical parameters using the extracted MPN.
  \item \textbf{PDF Retrieval}: If API data is incomplete or inconsistent, triggers the web-search and PDF parsing agent.
  \item \textbf{Validation}: Aggregates results, applies schema and physical checks, and resolves discrepancies.
  \item \textbf{Persistence}: On success, writes the validated record to PostgreSQL.
\end{enumerate}

\paragraph{Error Handling and Retries}
Each node can emit a \texttt{failure} edge, which routes the workflow to a retry or fallback node. For example, if the Octopart API returns incomplete data, the graph transitions to the PDF retrieval stage. All exceptions and validation errors are logged in the state for observability.

\paragraph{Example Graph Definition (Python)}
\begin{figure}[H]
\centering
\begin{minipage}{0.95\textwidth}
\begin{verbatim}
with StateGraph() as g:
    mpn = g.add_node("mpn_extraction", mpn_extraction_tool)
    api = g.add_node("octopart_api", octopart_api_tool)
    pdf = g.add_node("pdf_retrieval", pdf_retrieval_tool)
    val = g.add_node("validation", validation_tool)
    persist = g.add_node("persistence", persistence_tool)

    g.connect(mpn, api)
    g.connect(api, val)
    g.connect(val, persist)
    g.connect(val, pdf, condition=needs_pdf_fallback)
    g.connect(pdf, val)
\end{verbatim}
\end{minipage}
\caption{Abbreviated LangGraph definition showing agent nodes and conditional transitions.}
\end{figure}

\paragraph{Benefits}
This graph-based orchestration provides:
\begin{itemize}
  \item \textbf{Transparency}: Each stage and transition is explicit and auditable.
  \item \textbf{Extensibility}: New agents or validation steps can be added with minimal changes.
  \item \textbf{Robustness}: Failures are isolated and handled via fallback paths, improving reliability.
  \item \textbf{Stateful Coordination}: Shared state enables complex, multi-step reasoning and provenance tracking.
\end{itemize}

The LangGraph approach thus enables modular, maintainable, and observable orchestration of the multi-agent enrichment pipeline.


%--------------------------------------------------
\section{Summary}
This chapter translated the high-level architecture into concrete implementation artefacts: Python modules, prompts, deployment scripts, and observability tooling.  The next chapter evaluates how well these design choices satisfy the performance and accuracy requirements defined earlier.