\chapter{Conclusion}
\label{chapter:conclusion}

%--------------------------------------------------
\section{Summary of Work}
This thesis proposed and implemented a multi-agent system that converts noisy quotation-template entries into validated, structured component specifications.  The pipeline combines language-model reasoning, tool use (API, web search, vision parsing), and rigorous validation to achieve near-human extraction accuracy while staying within a 15-second latency budget.

%--------------------------------------------------
\section{Answers to Research Questions}

\textbf{Component identifier extraction}: The agent achieved an accuracy of 0.97, substantially higher than the RegexOnly baseline of 0.63.

\textbf{Datasheet \& metadata retrieval}: Using a cooperative API and web approach, the system reached a field coverage rate of 0.79, compared to 0.27 for APIOnly.

\textbf{Parameter extraction}: The pipeline achieved near-human accuracy on all five key parameters, with field-level accuracy ranging from 0.79 to 0.93 and large gains over the PyPDF2 baseline.

All targets defined in Chapter~\ref{chapter:problem} were met or exceeded.

%--------------------------------------------------
\section{Contributions}
\begin{itemize}
  \item A fault-tolerant orchestration of specialised LLM agents leveraging external tools.
  \item An open-sourced evaluation corpus and metrics for quotation-template processing.
  \item Demonstration, via the cost modelling example, of how enabling downstream analytics depends on the availability of structured specifications produced by the proposed system.
\end{itemize}

%--------------------------------------------------
\section{Future Directions}
In addition to the directions discussed in Chapter~\ref{chapter:discussion}, several further avenues could strengthen and extend the multi-agent data enrichment system:
\begin{itemize}
  \item \textbf{Human–AI collaboration}: Integrate user-facing workflows and interfaces that allow engineers to review, correct, or confirm extracted data with minimal friction. Wrapping these capabilities into the existing toolset will enable efficient human-in-the-loop validation and continuous improvement of extraction quality.
  \item \textbf{Cost model feedback}: Use the cost model not only for downstream analytics, but as an active feedback signal for data enrichment. For example, when the cost model detects anomalous predictions or high uncertainty, the system can trigger targeted re-extraction, additional validation, or human review for those specific cases—closing the loop between analytics and data quality.
  \item \textbf{Broader tool integration}: Expand the system by wrapping and integrating additional tools—such as advanced OCR, web scraping, or CAD parsers—within the multi-agent framework. This will further increase coverage, robustness, and the ability to handle diverse data sources and formats.
\end{itemize}

%--------------------------------------------------
\section{Closing Remarks}
By demonstrating that large-scale language and vision models can be orchestrated into a reliable, auditable pipeline, this work lays a foundation for next-generation procurement analytics.  Continued advances in multimodal LLMs and cost-efficient inference will only amplify the impact of such systems.