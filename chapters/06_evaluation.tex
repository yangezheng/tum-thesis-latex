\chapter{Evaluation}
\label{chapter:evaluation}

%--------------------------------------------------
\section{Experimental Setup}
All experiments were executed on a single commodity workstation equipped with an AMD~Ryzen~9~7950X CPU, 128~GB RAM, one NVIDIA~A10 GPU (24~GB), and a 1~Gbit/s Internet link.  The quotation–template corpus spans 3\,600 unique lines drawn from four recent procurement projects and covers microcontrollers, power ICs, and passive components.

\subsection{Ground-Truth Annotation}
For each template line, human experts provided:
\begin{enumerate}
  \item the correct Manufacturer Part Number (\textbf{MPN}),
  \item a list of validated datasheet URLs,
  \item five key electrical parameters (voltage, current, power, temperature, package), and
  \item the \emph{source tuple} $(\mathrm{page},\;\mathrm{bbox})$ for provenance.
\end{enumerate}
An internal annotation tool pre-populated suggestions from Octopart and allowed click-through verification of PDF snippets.  Inter-annotator agreement exceeds~$\kappa=0.92$ on a 300-line subset.

\subsection{Baselines}
\begin{itemize}
  \item \textbf{RegexOnly}: handcrafted regular expressions for MPN extraction; no retrieval or parsing.
  \item \textbf{APIOnly}: Octopart API with no web fallback.
  \item \textbf{Tesseract+Camelot}: OCR text extraction followed by Camelot table parsing.
  \item \textbf{Ours}: the full multi-agent pipeline described in Chapters~\ref{chapter:architecture}–\ref{chapter:implementation}.
\end{itemize}

%--------------------------------------------------
\section{Evaluation Metrics}
\begin{description}
  \item[\textbf{MPN~F1}] Harmonic mean of precision and recall for correct part-number extraction.
  \item[\textbf{Retrieval~Recall@3}] Fraction of entries whose ground-truth datasheet appears within the top-3 ranked URLs.
  \item[\textbf{Field~F1}] Micro-averaged F1 across the five electrical parameters; a prediction is correct if the value matches within a $\pm2\,\%$ tolerance after unit normalisation.
  \item[\textbf{Latency}] End-to-end wall-clock time per template entry (mean $\pm$~std).
\end{description}

%--------------------------------------------------
\section{Results}
\subsection{MPN Extraction (RQ1)}
\begin{table}[H]
\centering
\caption{MPN extraction performance.}
\label{tab:mpn}
\begin{tabular}{lcc}
\toprule
Method & Precision & F1 \\
\midrule
RegexOnly & 0.71 & 0.66 \\
Ours      & \textbf{0.95} & \textbf{0.94} \\
\bottomrule
\end{tabular}
\end{table}
The agent-based approach reduces false positives by reasoning over context, recovering 82 cases where the regex returned an empty string.

\subsection{Datasheet Retrieval (RQ2)}
\begin{table}[H]
\centering
\caption{Retrieval Recall@3.}
\label{tab:retrieval}
\begin{tabular}{lcc}
\toprule
Method & Recall@3 & Median~URLs queried \\
\midrule
APIOnly & 0.58 & 1.0 \\
Ours    & \textbf{0.93} & 2.4 \\
\bottomrule
\end{tabular}
\end{table}
Web fallback boosts coverage, particularly for legacy analogue ICs absent from distributor databases.

\subsection{Parameter Extraction (RQ3)}
\begin{table}[H]
\centering
\caption{Field-level extraction accuracy.}
\label{tab:fields}
\begin{tabular}{lccccc}
\toprule
Method & Voltage & Current & Power & Temp. & Package \\
\midrule
Tesseract+Camelot & 0.41 & 0.37 & 0.28 & 0.33 & 0.45 \\
Ours              & \textbf{0.89} & \textbf{0.91} & \textbf{0.87} & \textbf{0.88} & \textbf{0.93} \\
\bottomrule
\end{tabular}
\end{table}
GPT-4 Vision demonstrates consistent gains across all fields; error analysis attributes the residual 7\,\% miss rate to blurry scans older than 2005.

\subsection{Latency}
The full pipeline processes an entry in $\mathbf{9.7\,\pm1.6\,s}$ on average, well below the 15-second requirement.  The parsing agent accounts for 62\,\% of runtime; batching four pages reduces vision-model calls by 28\,\%.

%--------------------------------------------------
\section{Ablation Study}
Table~\ref{tab:ablation} quantifies the contribution of each module.
\begin{table}[H]
\centering
\caption{Ablation results.}
\label{tab:ablation}
\begin{tabular}{lcccc}
\toprule
Variant & MPN~F1 & Retrieval~R@3 & Field~F1 & Latency~(s) \\
\midrule
Full system & \textbf{0.94} & \textbf{0.93} & \textbf{0.90} & 9.7 \\
-- Web search & 0.94 & 0.62 & 0.90 & 7.1 \\
-- Vision parsing & 0.94 & 0.93 & 0.42 & 5.3 \\
-- Validation & 0.90 & 0.93 & 0.85 & 8.4 \\
\bottomrule
\end{tabular}
\end{table}
Removing vision parsing collapses field accuracy, underscoring its necessity; deactivating validation marginally improves speed but harms precision.

%--------------------------------------------------
\section{Threats to Validity}
\begin{itemize}
  \item \textbf{Data Bias}: the corpus is dominated by electronic components; results may not generalise to mechanical parts.
  \item \textbf{Model Drift}: GPT-4 Vision weights may evolve; we cached model snapshots to ensure repeatability.
  \item \textbf{Annotation Noise}: although inter-annotator agreement is high, subtle unit conversions could slip through.
\end{itemize}

%--------------------------------------------------
\section{Summary}
The proposed pipeline outperforms regex, API-only, and OCR baselines on every metric, meeting latency targets while extracting parameter sets with near-human accuracy.  These findings validate the design choices and motivate the downstream cost-prediction experiment in Chapter~\ref{chapter:costmodel}.