\chapter{Evaluation}
\label{chapter:evaluation}

%--------------------------------------------------
\section{Experimental Setup}
All experiments were conducted on a MacBook Pro 16-inch with an Apple M2 Pro processor and 16~GB RAM. The quotationâ€“template corpus consists of 800 unique lines drawn from four recent procurement projects, covering microcontrollers, power ICs, and passive components.

\subsection{Ground-Truth Annotation}
Each template line was manually annotated to establish high-quality ground truth. The annotation process consisted of:
\begin{enumerate}
  \item Identifying the correct component identifier,
  \item Compiling a list of 26 technical parameters for each part,
  \item Recording the values of five key electronic parameters: voltage, current, power, number of pins, and package.
\end{enumerate}
Annotations were performed by carefully reading datasheets and entering the required information into a structured spreadsheet.

\subsection{Baselines}
To fairly assess the performance of our end-to-end pipeline, we compare against several strong baselines, each representing a classical or ablated approach:
\begin{itemize}
  \item \textbf{RegexOnly}: Applies handcrafted regular expressions to extract the component identifier from text, isolating the challenge of identifier extraction without any model-based reasoning.
  \item \textbf{GPT-3.5 (various zero/multi-shot settings)}: Includes zero-shot ($T=0.0$), zero-shot ($T=0.7$), and multi-shot ($T=0.7$) variants of GPT-3.5 for component identifier extraction. This group of baselines demonstrates the effect of prompt engineering and decoding strategy on LLM-based extraction, and provides a fair comparison to our method.
  \item \textbf{APIOnly}: Directly queries the Octopart API using the extracted component identifier, without attempting web search or PDF fallback if the API response is incomplete. This simulates a typical single-source retrieval workflow, lacking robustness to missing or partial data.
  \item \textbf{PyPDF2}: Uses the PyPDF2 Python library to extract all text from datasheet PDFs, then applies rule-based heuristics (regular expressions and keyword matching) to identify and extract technical parameters. No language model or agent-based reasoning is used, simulating a fully classical, non-LLM pipeline for end-to-end extraction.
\end{itemize}

%--------------------------------------------------
\section{Evaluation Metrics}
\begin{description}
  \item[\textbf{Identifier~Accuracy}] Fraction of entries for which the extracted component identifier exactly matches the ground truth. (Compared between RegexOnly, GPT-3.5 variants, and Ours.)
  \item[\textbf{Field Coverage Rate}] Average number of non-null fields per row, divided by the total possible fields (26). (Compared between APIOnly and Ours.)
  \item[\textbf{Field~F1}] For the five most important technical parameters, the proportion extracted correctly; a parameter is considered correct if its value matches the ground truth within a $\pm2\,\%$ tolerance after unit normalisation. (Compared between PyPDF2 and Ours.)
\end{description}

%--------------------------------------------------
\section{Results}
\subsection{Component Identifier Extraction (RQ1)}
\begin{table}[H]
\centering
\caption{Component identifier extraction performance (RegexOnly, GPT-3.5 variants).}
\label{tab:mpn}
\begin{tabular}{lc}
\toprule
Method & Identifier~Accuracy \\
\midrule
RegexOnly                        & 0.63 \\
GPT-3.5~(Zero-Shot, $T=0.7$)     & 0.85 \\
GPT-3.5~(Zero-Shot, $T=0.0$)     & 0.87 \\
GPT-3.5~(Multi-Shot, $T=0.7$)    & 0.96 \\
Ours (GPT-3.5, Multi-Shot, $T=0.0$)       & \textbf{0.97} \\
\bottomrule
\end{tabular}
\end{table}
Our agent-based pipeline achieves substantially higher identifier accuracy than RegexOnly. RegexOnly often fails on non-standard formats, while our method is robust to such variations.

\subsection{Field Coverage Rate (RQ2)}
\begin{table}[H]
\centering
\caption{Field coverage rate (APIOnly vs. Ours).}
\label{tab:coverage}
\begin{tabular}{lc}
\toprule
Method & Field Coverage Rate \\
\midrule
APIOnly   & 0.27 \\
Ours      & \textbf{0.79} \\
\bottomrule
\end{tabular}
\end{table}
Our pipeline achieves much higher field coverage than APIOnly, which is limited by incomplete distributor data and does not attempt fallback strategies.

\subsection{Parameter Extraction (RQ3)}
\begin{table}[H]
\centering
\caption{Field-level accuracy for key parameters.}
\label{tab:fields}
\begin{tabular}{lccccc}
\toprule
Method & Package & Pins & Max Vin & Min Vin & Iout \\
\midrule
PyPDF2    & 0.49 & 0.45 & 0.26 & 0.21 & 0.24 \\
Ours      & \textbf{0.93} & \textbf{0.91} & \textbf{0.81} & \textbf{0.79} & \textbf{0.82} \\
\bottomrule
\end{tabular}
\end{table}
Our pipeline delivers near-human accuracy on all five key parameters, with the largest gains observed for power and package fields. The PyPDF2 baseline struggles with ambiguous layouts and inconsistent units.

\section{Threats to Validity}
\begin{itemize}
  \item \textbf{Data Bias}: While datasheets for electronic components are often easier to parse due to their semi-structured format, this may inflate performance metrics and limit generalisability to domains such as mechanical parts, which typically have more variable and unstructured documentation.
  \item \textbf{Model Drift}: The GPT-4o model used for PDF parsing may change over time; to mitigate this, outputs were cached at evaluation time.
  \item \textbf{Annotation Noise}: All ground-truth annotations were performed by a single expert, so some undetected errors may remain.
\end{itemize}

%--------------------------------------------------
% Insert Cost Model analysis as part of Evaluation
\input{chapters/07_costmodel}

%--------------------------------------------------
\section{Summary}
The proposed pipeline consistently outperforms regex, API-only, and PyPDF2 baselines in both extraction accuracy and robustness, achieving near-human performance on key parameter fields. Furthermore, by leveraging the high-quality structured data produced by the pipeline, a gradient boosting regressor is able to predict MOSFET prices with strong accuracy ($R^2 = 0.84$) and low mean absolute error, demonstrating that the extracted specifications are not only accurate but also actionable for downstream cost modelling. These results highlight the pipeline's effectiveness in both data extraction and enabling reliable price prediction, supporting its value for procurement and engineering workflows.