\chapter{Problem Setting}
\label{chapter:problem}

\section{Characteristics of quotation analysis templates}
A standardised quotation analysis template is a semi-structured document exchanged during early supplier negotiations.  
In many companies, such templates appear in spreadsheet format.  
Typical fields include:  

\begin{itemize}
  \item \textbf{Part Designation:} free-text description (e.\,g., ``STM32F103C8 MCU 64\,KB Flash TQFP48''),
  \item \textbf{Price and MOQ:} preliminary unit price, minimum order quantity,
\end{itemize}

The challenge lies in the Part Designation column, which often combines technical specifications and the manufacturer part number (MPN) into a single free-text field.
This lack of structure, along with multilingual notations (e.g., Gehäuse'', Temp. Bereich''), complicates rule-based parsing.

\section{Core Challenges}
\paragraph{C1: Inconsistent Identifier Extraction}  
An MPN may be surrounded by package codes (``\texttt{-TR}''), voltage values, or marketing text, making pattern-matching unreliable.  
Example:  
\begin{center}
\ttfamily PI3USB9281ZLE\_EX   20V Vbus Switch, TQFN-14, -40–85°C
\end{center}

\paragraph{C2: Missing Identifier-to-Parameter Mapping}
Even after correctly extracting an MPN, there is no comprehensive public or commercial database that reliably maps part numbers to their technical parameters—not even major distributors provide complete coverage.
This forces systems to extract parameters directly from datasheets, introducing additional complexity and dependence on document parsing.

\paragraph{C3: Datasheet Discovery and Access}
Locating a reliable datasheet for a given MPN involves searching across:
\begin{enumerate}
\item manufacturer websites (high trust),
\item distributor platforms (moderate trust),
\item third-party mirrors (low trust, often behind captchas or broken links).
\end{enumerate}
Selecting the most reliable source requires balancing trust, accessibility, and past success rates.

\paragraph{C4: Parameter Extraction from Unstructured Documents}
Datasheets are often long, unstructured PDFs with inconsistent formatting.
Technical parameters may appear in dense tables, inline text, or charts, and standard extraction tools frequently miss context, units, or formatting—compromising accuracy.

\paragraph{C5: Parameter Alignment Across Sources}
Technical specifications for a given part may be scattered across multiple sources—for example, partially listed on a distributor's website and partially extracted from the manufacturer's datasheet.
These representations often differ in terminology, format, precision, or units.
Reconciling this fragmented information requires normalization, deduplication, and conflict resolution to generate a consistent and accurate parameter set.

\paragraph{C6: Provenance and Traceability Requirements}
For safety-critical or compliance-sensitive applications, it's not enough to extract technical parameters—each value must be traceable to its original source.
This includes metadata such as the document name, page number, table or bounding box location, and source type (e.g., datasheet vs. distributor site).
Lack of provenance undermines trust in the extracted data and complicates manual verification or auditing by engineers.

\section{Formal Problem Definition}
Let $q \in \mathcal{Q}$ denote a single template entry containing noisy text tokens.  
The task is to compute a validated specification record  
\[
\mathbf{s} = \bigl(\mathrm{MPN},\; \mathrm{Voltage_{max}},\; \mathrm{Current_{max}},\; \mathrm{TempRange},\dots\bigr)
\]  
such that:

\begin{enumerate}
  \item \textbf{Correctness:} each numeric field equals the value printed in the authoritative datasheet.
  \item \textbf{Completeness:} mandatory fields are present; optional fields are \texttt{null} if not in the document.  
  \item \textbf{Provenance:} each field is traceable to its source, including its source, document name, page number.
  \item \textbf{Latency:} average end-to-end processing time $<15$ s per template.  
\end{enumerate}

\section{Automation Requirements}
Derived from the challenges and formal criteria, the target system must:

\begin{enumerate}
\item \textbf{R1: Noise-Tolerant Identifier Extraction} – Accurately extract MPNs from unstructured, noisy part designation strings, despite the presence of packaging codes, technical descriptors, or marketing language (addresses C1).

\item \textbf{R2: No-Schema Parameter Discovery} – Support parameter extraction even in the absence of a structured identifier-to-parameter mapping, by relying on downstream datasheet parsing (addresses C2).

\item \textbf{R3: Resilient Datasheet Retrieval} – Retrieve datasheets from a mix of trusted and unreliable sources, prioritizing success rate and content reliability while handling captchas, dead links, and inconsistent formats (addresses C3).

\item \textbf{R4: Multi-Source Parameter Fusion} – Normalize and reconcile parameter values found across datasheets and distributor sites, resolving differences in naming, units, and precision to generate a coherent specification set (addresses C5).

\item \textbf{R5: Structured Parameter Extraction} – Accurately extract parameter values from unstructured documents (PDFs), handling tables, prose, and visual elements using multi-modal models (addresses C4).

\item \textbf{R6: End-to-End Traceability} – Track and store detailed provenance for each parameter, including source URL, document page, and bounding box, to support validation, auditing, and engineer trust (addresses C6).
\end{enumerate}


% mapping
% \begin{description}
%   \item[RQ1.] How accurately can a language-model agent extract correct MPNs from semi-structured standardised quotation analysis template strings?
%   \item[RQ2.] Can cooperative retrieval agents-one using a distributor API, the other web search—achieve near-complete datasheet coverage across diverse suppliers and part formats??
%   \item[RQ3.] What precision and recall can a vision-language parsing agent attain on key electrical specifications?
%   \item[RQ5.] How can the system be designed to ensure traceability and provenance of extracted data?
% \end{description}


\section{Mapping Challenges to Research Questions}
\begin{center}
\begin{tabular}{lll}
\textbf{Challenge} & \textbf{Requirement} & \textbf{Mapped RQ} \\\hline
C1 & R1 & RQ1  \\
C4 & R5 & RQ2  \\
C5 & R4 & RQ3  \\
C6 & R6 & RQ4  \\
\textit{(Cross-cutting)} & R6 & All RQs (system-level trade-offs) \\
\end{tabular}
\end{center}


This mapping clarifies how each experimental evaluation in later chapters directly addresses a pain point in industrial procurement workflows.
