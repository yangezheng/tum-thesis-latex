\chapter{Introduction}\label{chapter:introduction}

%--------------------------------------------------
\begin{figure}[H]
  \centering
  \fbox{\begin{minipage}{0.95\textwidth}
  \textbf{Example Material Pricing Sheet line (synthetic)}\\[0.5em]
  \texttt{
  10UF 25V X5R 0603 C1608X5R1E106K080AC RoHS Reel 4000pcs \$0.073
  }
  \end{minipage}}
  \caption{Typical supplier-submitted Material Pricing Sheet line (synthetic example).}
  \label{fig:standardised-quotation-analysis-template-line-example}
\end{figure}

\section{Background }
The digitalisation of automotive supply chains has accelerated in recent years, yet many data-critical workflows still depend on semi-structured documents and manual interpretation.  
A common example is the \emph{Material Pricing Sheet}, a file exchanged during supplier negotiations that lists part designations, preliminary prices, delivery conditions, and essential technical details.  
While these templates often contain something resembling a component identifier, suppliers frequently embed the identifier within longer descriptive strings—mixing in electrical characteristics, packaging, and ordering information—or sometimes omit it altogether.  
As illustrated in Figure~\ref{fig:standardised-quotation-analysis-template-line-example}, each line typically appears as a single, unstructured entry that combines multiple attributes in free-form text.  
This lack of structure means engineers must manually inspect each line, identify or correct the component identifier, locate the corresponding datasheet, and extract key specifications—such as maximum voltage or operating temperature—for use in internal cost and qualification systems.  
With several thousand parts assessed per program phase, this \emph{ad hoc} process consumes hundreds of engineer-hours and remains susceptible to transcription errors.

The motivation for automating this process is clear: if we can reliably extract the component identifier from these noisy, unstructured lines, we can then retrieve authoritative technical parameters from datasheets or databases. Once structured technical data is available, it enables a wide range of downstream applications, such as automated price prediction, CO$_2$ emission estimation, and supplier risk analysis. In essence, accurate extraction and structuring of component information is a foundational step that unlocks advanced analytics and decision support, ultimately making procurement workflows more efficient, transparent, and scalable.

%--------------------------------------------------
\section{Problem Statement }
The overall challenge addressed in this thesis can be decomposed into three core technical problems:

\begin{enumerate}
    \item \textbf{Component Identifier Extraction:} Accurately extracting the component identifier from noisy and unstructured supplier text. Regular expressions are a common approach, but they are brittle—minor variations in formatting, inconsistent delimiters, or embedded product descriptions frequently cause extraction to fail. Furthermore, when a regular expression returns a null result, it is ambiguous whether no identifier is present or if the pattern simply failed to match a valid one.
    \item \textbf{Technical Parameter Retrieval:} Obtaining the relevant technical parameters (such as voltage, current, or temperature range) for a given component identifier. This typically requires locating the correct datasheet or authoritative database entry and extracting the required specifications, which is complicated by inconsistent document formats and incomplete coverage in public databases.
    \item \textbf{Downstream Application Construction:} Leveraging the structured technical data for downstream tasks, such as automated cost prediction, CO$_2$ estimation, or supplier risk analysis. These applications depend critically on the accuracy and completeness of the extracted and validated component information, but are not part of the system itself—they serve as motivating examples of what becomes possible once the data is structured.
\end{enumerate}

Addressing these problems requires a holistic approach that goes beyond simple pattern matching. For the first problem, large language models~(LLMs) offer a more robust alternative to regular expressions by reasoning over free-form text and recognizing contextual cues, enabling them to identify component identifiers even when embedded in descriptive strings or surrounded by supplier-specific notations.

For the second problem, the system must reliably retrieve and extract technical parameters. This involves not only locating the correct datasheet or database entry, but also parsing diverse and inconsistently formatted documents—tasks that benefit from a combination of web search, API integration, and advanced extraction techniques such as vision-language models.

While downstream applications are not part of the data enrichment pipeline system described in this thesis, a custom cost-prediction model was implemented solely as an illustrative example. The core focus remains on the first two problems: extracting component identifiers and retrieving technical parameters, which together establish the foundation for future analytics and automation use cases.

%--------------------------------------------------
\section{Research Objectives }
The central objective of this thesis is to design, implement, and evaluate a \textbf{reliable multi-agent system} that transforms noisy inputs from Material Pricing Sheets into validated, structured component inforamtion.  
To operationalise this goal, the work addresses three research questions:

\begin{description}
\item[\textbf{RQ1.}] How accurately can a language-model agent extract component identifiers from noisy, multilingual part designation fields in semi-structured Material Pricing Sheets?

\item[\textbf{RQ2.}] How reliably can web-search agents retrieve the correct PDF datasheet for a given part, especially when distributor APIs are incomplete or unavailable?

\item[\textbf{RQ3.}] How accurately can technical parameters be extracted from retrieved datasheets using vision-language models or other automated methods?
\end{description}

%--------------------------------------------------
\section{Proposed Approach }
To answer these questions, the thesis proposes a modular pipeline whose agents each address a single sub-task:  
\begin{enumerate}
  \item A \textbf{Component Identifier Extraction Agent} uses GPT-4 with prompt engineering and regex to isolate the component identifier from quotation template text.  
  \item Two \textbf{Retrieval Agents} operate in parallel:
    \begin{itemize}
      \item[(i)] An \emph{API Agent} queries the Octopart distributor API to obtain structured part metadata and datasheet links.
      \item[(ii)] A \emph{Datasheet Agent} performs a Google-based search to locate datasheet PDFs directly, prioritising high-confidence domains (e.g., manufacturer or distributor sites). And leverages Vision Language Models (VLMs) to extract the key electrical specifications from the retrieved datasheets.
    \end{itemize}
  \item A \textbf{Validation Module} enforces JSON-Schema constraints and physical range rules and flags low-confidence extractions for manual review.  
  \item Finally, a \textbf{Cost-Prediction Model} is trained on the extracted specifications, demonstrating the economic value of the pipeline's output.
\end{enumerate}

%--------------------------------------------------
\section{Contribution }
The thesis offers three concrete contributions:
\begin{enumerate}
  \item A fault-tolerant multi-agent framework that integrates LLMs, web search, distributor APIs, and VLM parsing into a single orchestrated workflow.  
  \item Empirical benchmarks reporting component identifier extraction accuracy, datasheet retrieval success, field-level precision/recall, and end-to-end latency.  
  \item A downstream cost-prediction experiment showing that structured specs extracted by the system provide price-estimation, thus underlining direct business impact.
\end{enumerate}

%--------------------------------------------------
\section{Thesis Structure }
The remainder of this document is organised as follows:  
Chapter~\ref{chapter:relatedwork} surveys literature on language-model agents, vision-language models, and document AI in procurement.  
Chapter~\ref{chapter:problem} formalises the challenges inherent to Material Pricing Sheet processing.  
Chapter~\ref{chapter:architecture} details the proposed multi-agent architecture, while Chapter~\ref{chapter:implementation} describes implementation specifics, including prompts, API wrappers, and validation logic.  
Chapter~\ref{chapter:evaluation} presents the experimental setup and quantitative results.  
Section~\ref{chapter:costmodel} demonstrates the downstream cost-modelling application.  
Chapter~\ref{chapter:discussion} reflects on limitations and industrial implications, and Chapter~\ref{chapter:conclusion} concludes the thesis with avenues for future work.
